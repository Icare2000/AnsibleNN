#Install basic from NN
- name: Install basics from Nespresso
  hosts: kraft_servers
  become: yes
  tasks:
    - name: Install MC
      apt:
        name: mc
        state: present      
        update_cache: yes

- name: Check Kraft
  hosts: kraft_servers
  tasks:
  debug:
    msg: "This is to gather facts from spark"
    var: ansible_facts


#Installing Apache Kafka (Zookeeper&Brokers)
- name: Install and Configure Zookeeper & Brokers
  hosts: kraft_servers, brokers
  become: yes
  vars:
    jdk_version: openjdk-8-jre
    kafka_path: /etc/kafka
    zookeeper_data_dir: /var/lib/zookeeper/data 
    zookeeper_port: 2181
    kafka_heap_size: -Xmx520M -Xms520M
    zookeeper_heap_size: -Xmx528M -Xms528M
    kafka_vers: 3.6.0
    scala_vers: 2.13
    kafka_url: https://downloads.apache.org/kafka/{{kafka_vers}}/kafka_{{scala_vers}}-{{kafka_vers}}.tgz
  tasks:
    # - name: Install JDK (OpenJDK)
    #   apt:
    #     name: "{{jdk_version}}"
    #     state: present      
    #     update_cache: yes

    - name: create kafka user
      user:
        name: kafka
        shell: /bin/false

    - name: build kafka directory structures
      file:
        path: "{{ item }}"
        state: directory
        owner: kafka
        group: kafka
        mode: 0750
        recurse: yes
      loop:
        - "{{ kafka_path }}/kafka_{{scala_vers}}-{{kafka_vers}}/logs/kraft-combined-logs"
       # - "{{ kafka_log_dir }}"
        
    - name: download kafka source
      get_url:
        url: "https://downloads.apache.org/kafka/{{kafka_vers}}/kafka_{{scala_vers}}-{{kafka_vers}}.tgz"
        dest: /tmp/kafka_{{scala_vers}}-{{kafka_vers}}.tgz

    - name: expand tarball to source folder
      unarchive:
        src: "/tmp/kafka_{{scala_vers}}-{{kafka_vers}}.tgz"
        dest: "{{ kafka_path }}"
        remote_src: yes
        owner: root
        group: root
        mode: 0640
      notify: enforce kafka permissions
    - name: symlink kafka dirs to latest
      file:
        state: link
        src: "{{ kafka_path }}/kafka_{{scala_vers}}-{{kafka_vers}}"
        dest: "{{ kafka_path }}/latest"
    
    - name: set execute bit on files in bin dir
      file:
        path: "{{ kafka_path }}/kafka_{{scala_vers}}-{{kafka_vers}}/bin/"
        state: directory
        mode: 0750
        recurse: yes

    # - name: install kafka service systemd unit file
    #   template:
    #     src: ../templates/confluent-server.service.j2
    #     dest: /etc/systemd/system/confluent-server.service
    #     owner: root
    #     group: root
    #     mode: 0644
    #   notify: reload systemd

    - name: render kakfa service config file
      template:
        src: ../templates/server.properties.j2
        dest: "{{ kafka_path }}/latest/config/kraft/server.properties"
        owner: kafka
        group: kafka
        mode: 0640
        backup: yes
      notify: restart kafka service

    - name: add kafka bin path to all users' PATH
      template:
        src: ../templates/kafka_path.sh.j2
        dest: /etc/profile.d/kafka_path.sh
        owner: root
        group: root
        mode: 0644
        seuser: system_u
        serole: object_r
        setype: bin_t
        selevel: s0

    - name: check if kraft logs dir has been initialized
      shell: "{{ kafka_path }}/latest/bin/kafka-storage.sh info -c {{ kafka_path }}/latest/config/kraft/server.properties"
      register: storage_init
      ignore_errors: yes

    - name: init kraft logs dir
      shell: "{{ kafka_path }}/kafka_{{scala_vers}}-{{kafka_vers}}/bin/kafka-storage.sh format -t {{ kafka_cluster_id }} -c {{ kafka_path }}/kafka_{{scala_vers}}-{{kafka_vers}}/config/kraft/server.properties"
      when: '"is not formatted" in storage_init.stdout'

    # - name: start and enable kafka service service
    #   systemd:
    #     name: confluent-server
    #     state: started
    #     enabled: yes





  handlers:
    - name: reload systemd
      systemd:
        daemon_reload: yes

    - name: enforce kafka permissions
      file:
        path: "{{ kafka_path }}"
        state: directory
        owner: kafka
        group: kafka
        mode: 0750
        recurse: yes
      
    - name: restart kafka service
      systemd:
        name: confluent-server
        state: restarted
  # #Configuring Zookeeper Ensemble     
  #   - name: Configure ZooKeeper Properties
  #     template:
  #       src: zb_zookeeper_properties.j2
  #       dest: "{{kafka_path}}/config/zookeeper.properties"
  #     when: inventory_hostname in groups['zookeepers']
  
  #   - name: Create ZooKeeper data directory
  #     file:
  #      path: "{{ zookeeper_data_dir }}"
  #      state: directory
  #      mode: 0755
  #      recurse: yes
  #      owner: kafka
  #      group: kafka
  #     when: inventory_hostname in groups['zookeepers']
  
  #   - name: Create ZooKeeper myid file with unique incremental values
  #     copy:
  #       content: "{{ hostvars[inventory_hostname]['myid'] }}"
  #       dest: "{{zookeeper_data_dir}}/myid"
  #     when: inventory_hostname in groups['zookeepers']
    
  #   - name: Update the Java Heap Size for Zookeepers
  #     replace:
  #         path: "{{kafka_path}}/bin/zookeeper-server-start.sh"
  #         regexp: 'export KAFKA_HEAP_OPTS=(".+")'
  #         replace: 'export KAFKA_HEAP_OPTS="{{zookeeper_heap_size}}"'
  #         backup: yes
  #     when: inventory_hostname in groups['zookeepers']    

  # #Configuring Kafka Brokers  
  #   - name: Configure Server Properties
  #     template:
  #       src: zb_server_properties.j2
  #       dest: "{{kafka_path}}/config/server.properties"
  #     when: inventory_hostname in groups['brokers']

  #   - name: Update the Java Heap Size for Kafka
  #     replace:
  #         path: "{{kafka_path}}/bin/kafka-server-start.sh"
  #         regexp: 'export KAFKA_HEAP_OPTS=(".+")'
  #         replace: 'export KAFKA_HEAP_OPTS="{{kafka_heap_size}}"'
  #         backup: yes
  #     when: inventory_hostname in groups['brokers']    
  
  # #Create a Service for Zookeeper
  #   - name: Create a Service file for ZooKeeper with Copy module
  #     copy:
  #       dest: /etc/systemd/system/zookeeper.service
  #       content: |
  #         [Unit]
  #         Requires=network.target remote-fs.target
  #         After=network.target remote-fs.target
  #         [Service]
  #         Type=simple
  #         User=kafka
  #         ExecStart=/bin/sh -c '{{kafka_path}}/bin/zookeeper-server-start.sh {{kafka_path}}/config/zookeeper.properties > {{zookeeper_data_dir}}/zookeeperservice.log 2>&1'
  #         ExecStop={{kafka_path}}/bin/zookeeper-server-stop.sh
  #         Restart=always  
  #         [Install]
  #         WantedBy=multi-user.target
  #       mode: 0755
  #     when: inventory_hostname in groups['zookeepers']

  # #Create a Service for Kafka  
  #   - name: Create a Service file for Kafka with Copy module
  #     copy:
  #       dest: /etc/systemd/system/kafka.service
  #       content: |
  #         [Unit]
  #         Requires=zookeeper.service
  #         After=zookeeper.service
  #         [Service]
  #         Type=simple
  #         User=kafka
  #         ExecStart=/bin/sh -c '{{kafka_path}}/bin/kafka-server-start.sh {{kafka_path}}/config/server.properties > {{kafka_path}}/kafkaservice.log 2>&1'
  #         ExecStop={{kafka_path}}/bin/kafka-server-stop.sh
  #         Restart=always
  #         [Install]
  #         WantedBy=multi-user.target
  #       mode: 0755
  #     when: inventory_hostname in groups['brokers']

  # #Daemon reload after creating services 
  #   - name: Systemctl daemon-reload after creation
  #     shell: systemctl daemon-reload

  # #Start & Check Service for Zookeepers
  #   - name: Start Zookeepers
  #     tags: startzookeepers
  #     systemd:
  #         name: 'zookeeper'
  #         state: started
  #         daemon_reload: true
  #         enabled: yes    
  #     when: inventory_hostname in groups['zookeepers'] 

  #   - name: Validating if zookeeper is up and listening on port 2181
  #     wait_for:
  #       host: "{{ ansible_host }}"
  #       port: 2181
  #       delay: 10
  #       timeout: 30
  #       state: started
  #       msg: "Zookeeper not seem to be running on {{ansible_host}}"
  #     when: inventory_hostname in groups['zookeepers']


  # #Start & Check Service for Kafka Brokers
  #   - name: Start Kafka Brokers
  #     tags: startkafkabrokers
  #     systemd:
  #       name: 'kafka'
  #       state: started
  #       daemon_reload: true
  #       enabled: yes
  #     when: inventory_hostname in groups['brokers']     
        
  #   - name: Validating if Kafka is up and listening on port 9092
  #     wait_for:
  #       host: "{{ ansible_host }}"
  #       port: 9092
  #       delay: 10
  #       timeout: 30
  #       state: started
  #       msg: "Kafka brokers do not seem to be running on {{ ansible_host }}"  
  #     when: inventory_hostname in groups['brokers']